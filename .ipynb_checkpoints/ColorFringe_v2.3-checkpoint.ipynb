{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5074320-2006-4e2b-8607-ad1901a4e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.widgets import Slider\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, FloatSlider, Output, RadioButtons\n",
    "\n",
    "from numpy.polynomial import Chebyshev\n",
    "\n",
    "from scipy.special import erf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1200c00-a184-411a-953c-751d7d0f2229",
   "metadata": {},
   "source": [
    "# Workflow for Color Fringe Computation and Chromatic Correction\n",
    "This document outlines the steps needed to simulate chromatic aberration effects, including data import, interpolation, interactive curve fitting, and analysis of color fringe width. The simulation takes into account the physics of chromatic aberration, sensor response, and overexposure effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc3e33-4183-42e6-8678-2d8588212b5a",
   "metadata": {},
   "source": [
    "## 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3765347e-81d9-44ec-b2ef-70188103da65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# CHLzf85 data points\n",
    "# Each row contains [wavelength (nm), defocus (Âµm)]\n",
    "CHLzf85 = np.array([\n",
    "    [400.0, 285.0],\n",
    "    [410.0, 190.0],\n",
    "    [420.0, 118.0],\n",
    "    [430.0, 63.0],\n",
    "    [440.0, 22.0],\n",
    "    [450.0, -9.0],\n",
    "    [460.0, -31.0],\n",
    "    [470.0, -46.0],\n",
    "    [480.0, -56.0],\n",
    "    [490.0, -62.0],\n",
    "    [500.0, -64.0],\n",
    "    [510.0, -63.0],\n",
    "    [520.0, -60.0],\n",
    "    [530.0, -54.0],\n",
    "    [540.0, -48.0],\n",
    "    [550.0, -39.0],\n",
    "    [560.0, -30.0],\n",
    "    [570.0, -20.0],\n",
    "    [580.0, -9.0],\n",
    "    [590.0, 3.0],\n",
    "    [600.0, 15.0],\n",
    "    [610.0, 28.0],\n",
    "    [620.0, 41.0],\n",
    "    [630.0, 54.0],\n",
    "    [640.0, 68.0],\n",
    "    [650.0, 82.0],\n",
    "    [660.0, 96.0],\n",
    "    [670.0, 111.0],\n",
    "    [680.0, 125.0],\n",
    "    [690.0, 139.0],\n",
    "    [700.0, 156.0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45543f11-ae01-4687-8023-41e8b504b177",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Daylight Spectrum shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "# Light Source Data\n",
    "# Each row contains [wavelength (nm), daylight value]\n",
    "or_Daylight = np.array([\n",
    "    [380, 11],\n",
    "    [390, 16],\n",
    "    [400, 22],\n",
    "    [410, 33],\n",
    "    [420, 48],\n",
    "    [430, 62],\n",
    "    [440, 71],\n",
    "    [450, 78],\n",
    "    [460, 84],\n",
    "    [470, 92],\n",
    "    [480, 97],\n",
    "    [490, 100],\n",
    "    [500, 96],\n",
    "    [510, 95],\n",
    "    [520, 95],\n",
    "    [530, 94],\n",
    "    [540, 90],\n",
    "    [550, 78],\n",
    "    [560, 70],\n",
    "    [570, 78],\n",
    "    [580, 88],\n",
    "    [590, 94],\n",
    "    [600, 91],\n",
    "    [610, 85],\n",
    "    [620, 82],\n",
    "    [630, 85],\n",
    "    [640, 92],\n",
    "    [650, 100],\n",
    "    [660, 89],\n",
    "    [670, 76],\n",
    "    [680, 83],\n",
    "    [690, 100]\n",
    "])\n",
    "\n",
    "# Optional: Print the shape and first few rows for verification\n",
    "print(\"Original Daylight Spectrum shape:\", or_Daylight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06aa126-ffc4-491f-b991-2d4ef5852be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SensorBlue shape: (31, 2)\n",
      "SensorGreen shape: (31, 2)\n",
      "SensorRed shape: (31, 2)\n"
     ]
    }
   ],
   "source": [
    "# Sensor data for each channel:\n",
    "# Each row contains [wavelength (nm), sensitivity]\n",
    "SensorBlue = np.array([\n",
    "    [400., 0.42],\n",
    "    [410., 9.08],\n",
    "    [420., 24.34],\n",
    "    [430., 28.37],\n",
    "    [440., 40.12],\n",
    "    [450., 39.01],\n",
    "    [460., 47.12],\n",
    "    [470., 46.65],\n",
    "    [480., 41.14],\n",
    "    [490., 26.73],\n",
    "    [500., 14.75],\n",
    "    [510., 7.55],\n",
    "    [520., 2.76],\n",
    "    [530., 0.],\n",
    "    [540., 0.],\n",
    "    [550., 0.],\n",
    "    [560., 0.],\n",
    "    [570., 0.],\n",
    "    [580., 0.],\n",
    "    [590., 0.],\n",
    "    [600., 0.],\n",
    "    [610., 0.],\n",
    "    [620., 0.],\n",
    "    [630., 0.],\n",
    "    [640., 0.],\n",
    "    [650., 0.],\n",
    "    [660., 0.69],\n",
    "    [670., 0.84],\n",
    "    [680., 0.32],\n",
    "    [690., 0.04],\n",
    "    [700., 0.]\n",
    "])\n",
    "\n",
    "SensorGreen = np.array([\n",
    "    [400., 0.],\n",
    "    [410., 0.],\n",
    "    [420., 0.],\n",
    "    [430., 0.],\n",
    "    [440., 0.],\n",
    "    [450., 0.],\n",
    "    [460., 0.],\n",
    "    [470., 4.63],\n",
    "    [480., 6.48],\n",
    "    [490., 9.09],\n",
    "    [500., 17.75],\n",
    "    [510., 28.39],\n",
    "    [520., 37.8],\n",
    "    [530., 38.39],\n",
    "    [540., 35.02],\n",
    "    [550., 28.83],\n",
    "    [560., 28.1],\n",
    "    [570., 19.02],\n",
    "    [580., 13.1],\n",
    "    [590., 6.96],\n",
    "    [600., 4.33],\n",
    "    [610., 3.34],\n",
    "    [620., 3.02],\n",
    "    [630., 0.],\n",
    "    [640., 0.],\n",
    "    [650., 0.],\n",
    "    [660., 0.69],\n",
    "    [670., 0.7],\n",
    "    [680., 0.34],\n",
    "    [690., 0.05],\n",
    "    [700., 0.]\n",
    "])\n",
    "\n",
    "SensorRed = np.array([\n",
    "    [400., 0.],\n",
    "    [410., 1.3],\n",
    "    [420., 1.86],\n",
    "    [430., 2.17],\n",
    "    [440., 1.73],\n",
    "    [450., 0.],\n",
    "    [460., 0.],\n",
    "    [470., 0.],\n",
    "    [480., 0.],\n",
    "    [490., 0.],\n",
    "    [500., 0.],\n",
    "    [510., 0.],\n",
    "    [520., 0.],\n",
    "    [530., 0.],\n",
    "    [540., 0.],\n",
    "    [550., 0.],\n",
    "    [560., 0.],\n",
    "    [570., 2.38],\n",
    "    [580., 60.18],\n",
    "    [590., 100.],\n",
    "    [600., 92.73],\n",
    "    [610., 72.75],\n",
    "    [620., 50.6],\n",
    "    [630., 35.81],\n",
    "    [640., 35.08],\n",
    "    [650., 22.4],\n",
    "    [660., 16.96],\n",
    "    [670., 7.75],\n",
    "    [680., 3.3],\n",
    "    [690., 0.78],\n",
    "    [700., 0.18]\n",
    "])\n",
    "\n",
    "# Optional: Print sensor data shapes to confirm successful import\n",
    "print(\"SensorBlue shape:\", SensorBlue.shape)\n",
    "print(\"SensorGreen shape:\", SensorGreen.shape)\n",
    "print(\"SensorRed shape:\", SensorRed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf94c5-7498-4e25-8798-ef7bcd1be271",
   "metadata": {},
   "source": [
    "## 2. Data Fitting and Common Sampling Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81ce230e-cbc7-4e96-981c-b6627899159c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted CHL coefficients: [ 6.17055255e-12 -2.17284405e-08  3.18690992e-05 -2.49424071e-02\n",
      "  1.09994225e+01 -2.59404221e+03  2.55683162e+05]\n",
      "Fitted CHL shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# CHL fit: polynomial of degree 6\n",
    "\n",
    "# x_CHL contains the wavelength values and y_CHL the corresponding CHL values from the dataset CHLzf85.\n",
    "x_CHL = CHLzf85[:, 0]\n",
    "y_CHL = CHLzf85[:, 1]\n",
    "\n",
    "# Fit a 6th-degree polynomial to the CHL data\n",
    "CHL_coeffs = np.polyfit(x_CHL, y_CHL, 6)\n",
    "\n",
    "# Define a function to evaluate the fitted polynomial at any given x (wavelength)\n",
    "def CHLFit(x):\n",
    "    # np.polyval evaluates the polynomial for the input x using coefficients in descending order\n",
    "    return np.polyval(CHL_coeffs, x)\n",
    "\n",
    "# Optional: Print the coefficients for inspection\n",
    "print(\"Fitted CHL coefficients:\", CHL_coeffs)\n",
    "\n",
    "x_fit = np.linspace(400, 700, 300)\n",
    "CHL_fit = CHLFit(x_fit)\n",
    "print(\"CHL_fit shape:\", CHL_fit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031342e6-babd-4608-8a0e-f8877fdc2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Daylight Spectrum: (31, 2)\n"
     ]
    }
   ],
   "source": [
    "# Light Source Fit: polynomial of degree 6 and resampling\n",
    "\n",
    "def resample_spectrum_poly(spectrum, new_wavelengths, degree=6):\n",
    "    # Separate the wavelength and intensity data\n",
    "    wavelengths = spectrum[:, 0]\n",
    "    intensities = spectrum[:, 1]\n",
    "    \n",
    "    # Fit a polynomial of the given degree to the data\n",
    "    coeffs = np.polyfit(wavelengths, intensities, degree)\n",
    "    poly_func = np.poly1d(coeffs)\n",
    "    \n",
    "    # Evaluate the polynomial at the new wavelengths\n",
    "    new_intensities = poly_func(new_wavelengths)\n",
    "\n",
    "    # Normalize the intensities so that the maximum is 100\n",
    "    max_intensity = np.max(new_intensities)\n",
    "    new_intensities = new_intensities / max_intensity * 100\n",
    "    \n",
    "    return np.column_stack((new_wavelengths, new_intensities))\n",
    "\n",
    "# Resample the spectrum using a 6th-degree polynomial fit\n",
    "Daylight = resample_spectrum_poly(or_Daylight, x_CHL, degree=6)\n",
    "\n",
    "# Print the resampled spectrum\n",
    "print(\"Resampled Daylight Spectrum:\", Daylight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be08de97-04a8-4374-aabd-97d0231067d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Blue sensor integral: 1.0\n",
      "Normalized Green sensor integral: 1.0000000000000002\n",
      "Normalized Red sensor integral: 1.0000000000000004\n",
      "SensorBlue_norm shape: (31, 2)\n",
      "SensorGreen_norm shape: (31, 2)\n",
      "SensorRed_norm shape: (31, 2)\n"
     ]
    }
   ],
   "source": [
    "# Extract wavelengths and daylight intensity\n",
    "wavelengths = Daylight[:, 0]\n",
    "daylight_intensity = Daylight[:, 1]\n",
    "\n",
    "# Define a helper function to compute normalization factor for a given sensor channel\n",
    "def compute_norm(sensor):\n",
    "    sensor_response = sensor[:, 1]\n",
    "    # Compute the integral using the composite trapezoidal rule\n",
    "    integral = np.trapezoid(sensor_response * daylight_intensity, x=wavelengths)\n",
    "    norm_factor = 1 / integral if integral != 0 else 0\n",
    "    return norm_factor, integral\n",
    "\n",
    "# Compute normalization factors for each sensor\n",
    "norm_factor_blue, integral_blue = compute_norm(SensorBlue)\n",
    "norm_factor_green, integral_green = compute_norm(SensorGreen)\n",
    "norm_factor_red, integral_red = compute_norm(SensorRed)\n",
    "\n",
    "# Apply normalization: each normalized sensor response satisfies\n",
    "# â« [NormalizedSensor(Î») * DaylightIntensity(Î»)] dÎ» = 1\n",
    "SensorBlue_norm = SensorBlue.copy()\n",
    "SensorGreen_norm = SensorGreen.copy()\n",
    "SensorRed_norm = SensorRed.copy()\n",
    "\n",
    "SensorBlue_norm[:, 1] *= norm_factor_blue\n",
    "SensorGreen_norm[:, 1] *= norm_factor_green\n",
    "SensorRed_norm[:, 1] *= norm_factor_red\n",
    "\n",
    "# Optionally, verify the integrals are now ~1 using np.trapezoid\n",
    "blue_integral_norm = np.trapezoid(SensorBlue_norm[:, 1] * daylight_intensity, x=wavelengths)\n",
    "green_integral_norm = np.trapezoid(SensorGreen_norm[:, 1] * daylight_intensity, x=wavelengths)\n",
    "red_integral_norm = np.trapezoid(SensorRed_norm[:, 1] * daylight_intensity, x=wavelengths)\n",
    "\n",
    "print(\"Normalized Blue sensor integral:\", blue_integral_norm)\n",
    "print(\"Normalized Green sensor integral:\", green_integral_norm)\n",
    "print(\"Normalized Red sensor integral:\", red_integral_norm)\n",
    "\n",
    "print(\"SensorBlue_norm shape:\", SensorBlue_norm.shape)\n",
    "print(\"SensorGreen_norm shape:\", SensorGreen_norm.shape)\n",
    "print(\"SensorRed_norm shape:\", SensorRed_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68cdf43-6fe6-4e50-a913-6a9fb666fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original lowest point at x = 501.34 nm, y = -63.42\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Core Functions & Global Array Access\n",
    "# Make sure that x_fit, CHLFit, x_CHL, y_CHL, and CHL_fit are defined in your environment.\n",
    "\n",
    "# Compute the wavelength interval (dx)\n",
    "dx = x_fit[1] - x_fit[0]\n",
    "\n",
    "# Find the original lowest point on the CHL curve (in the 400â700 nm range)\n",
    "x_min = x_fit[np.argmin(CHL_fit)]\n",
    "y_min = np.min(CHL_fit)\n",
    "print(\"Original lowest point at x = {:.2f} nm, y = {:.2f}\".format(x_min, y_min))\n",
    "\n",
    "def CHLFit_mod_overall(x_vals, x_shift=0.0, tilt=0.0):\n",
    "    \"\"\"\n",
    "    Returns the modified CHL curve with opposite tilts applied to each side of the pivot.\n",
    "    \"\"\"\n",
    "    pivot_x = x_min + x_shift\n",
    "    pivot_y = CHLFit(x_min)\n",
    "    \n",
    "    # Compute the horizontally shifted base curve.\n",
    "    x_shifted = x_vals - x_shift\n",
    "    base = CHLFit(x_shifted)\n",
    "    \n",
    "    # Compute numerical derivative.\n",
    "    dbase = np.gradient(base, dx)\n",
    "    \n",
    "    # Apply opposite tilt factors depending on side relative to the pivot.\n",
    "    new_deriv = np.empty_like(dbase)\n",
    "    for i, x in enumerate(x_vals):\n",
    "        if x < pivot_x:\n",
    "            new_deriv[i] = dbase[i] * (1 - tilt)\n",
    "        else:\n",
    "            new_deriv[i] = dbase[i] * (1 + tilt)\n",
    "    \n",
    "    # Integrate the new derivative.\n",
    "    g = np.empty_like(x_vals)\n",
    "    pivot_index = np.argmin(np.abs(x_vals - pivot_x))\n",
    "    g[pivot_index] = pivot_y\n",
    "    \n",
    "    # Integrate forward from the pivot.\n",
    "    for i in range(pivot_index + 1, len(x_vals)):\n",
    "        g[i] = g[i - 1] + new_deriv[i - 1] * dx\n",
    "    # Integrate backward from the pivot.\n",
    "    for i in range(pivot_index - 1, -1, -1):\n",
    "        g[i] = g[i + 1] - new_deriv[i + 1] * dx\n",
    "        \n",
    "    return g\n",
    "\n",
    "def extract_sampled_modified_values_overall(x_shift=0.0, tilt=0.0):\n",
    "    \"\"\"\n",
    "    Samples the modified CHL curve (with opposite tilts) every 10 nm between 400 and 700 nm.\n",
    "    Returns a 2-column matrix: [wavelength, integer CHL value].\n",
    "    \"\"\"\n",
    "    x_sample = np.arange(400, 701, 10)\n",
    "    y_sample = CHLFit_mod_overall(x_sample, x_shift, tilt)\n",
    "    y_sample_int = np.floor(y_sample)\n",
    "    return np.column_stack((x_sample, y_sample_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279f6158-e184-4dac-b2b3-b5491127860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 2: Imports, Data Setup, and Global Parameters\n",
    "SensorBluedata = SensorBlue_norm[:, 1]\n",
    "SensorGreendata = SensorGreen_norm[:, 1]\n",
    "SensorReddata = SensorRed_norm[:, 1]\n",
    "\n",
    "# Global constants and parameters\n",
    "K = 1.4\n",
    "xrange_val = 200    # Range for x values in plots\n",
    "defocusrange = 1000\n",
    "tol = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4fa4ce-1e34-435d-8570-2019987fcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Define Weighting Functions\n",
    "def linear_PSF(x, ratio):\n",
    "    if ratio < 1e-6:\n",
    "        return 1 if x >= 0 else 0\n",
    "    if x >= ratio:\n",
    "        return 1\n",
    "    elif x <= -ratio:\n",
    "        return 0\n",
    "    else:\n",
    "        return 0.5 * (1 + x / ratio)\n",
    "\n",
    "def gaussian_PSF(x, ratio):\n",
    "    if ratio < 1e-6:\n",
    "        return 1 if x >= 0 else 0\n",
    "    return 0.5 * (1 + erf(x / (np.sqrt(2) * ratio)))\n",
    "\n",
    "# Aliases for interactive selection\n",
    "ideal_weight = linear_PSF\n",
    "gaussian_weight = gaussian_PSF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "577dd741-4e12-47ac-a1ef-5f3f75a794a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 4: Core Calculation Functions\n",
    "def Exposure(x, F):\n",
    "    \"\"\"Generic edge function without spherical aberration.\"\"\"\n",
    "    return np.tanh(F * x) / np.tanh(F)\n",
    "\n",
    "def compute_edge(x, z, F, g, sensor_data, weight_func):\n",
    "    \"\"\"Compute the edge response for a given sensor channel.\"\"\"\n",
    "    denom_factor = np.sqrt(4 * K**2 - 1)\n",
    "    num = 0\n",
    "    for n in range(len(CHLdata)):\n",
    "        ratio = abs((z - CHLdata[n]) / denom_factor)\n",
    "        weight = weight_func(x, ratio)\n",
    "        num += sensor_data[n] * weight\n",
    "    den = np.sum(sensor_data)\n",
    "    return Exposure(num / den, F) ** g\n",
    "\n",
    "def EdgeR(x, z, F, g, weight_func):\n",
    "    \"\"\"Edge function for the red channel.\"\"\"\n",
    "    return compute_edge(x, z, F, g, SensorReddata, weight_func)\n",
    "\n",
    "def EdgeG(x, z, F, g, weight_func):\n",
    "    \"\"\"Edge function for the green channel.\"\"\"\n",
    "    return compute_edge(x, z, F, g, SensorGreendata, weight_func)\n",
    "\n",
    "def EdgeB(x, z, F, g, weight_func):\n",
    "    \"\"\"Edge function for the blue channel.\"\"\"\n",
    "    return compute_edge(x, z, F, g, SensorBluedata, weight_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aaa492b-162f-40d3-9405-1c7d49f6e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 5: Color Fringe and Binary Methods\n",
    "def Farbsaum(x, z, F, g, weight_func):\n",
    "    \"\"\"Binary method to determine color fringe (Farbsaum).\"\"\"\n",
    "    r = EdgeR(x, z, F, g, weight_func)\n",
    "    g_val = EdgeG(x, z, F, g, weight_func)\n",
    "    b = EdgeB(x, z, F, g, weight_func)\n",
    "    if abs(r - b) > tol or abs(r - g_val) > tol or abs(g_val - b) > tol:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def Farbsaumbreite(z, F, g, weight_func):\n",
    "    \"\"\"Calculate overall color fringe width using the binary method.\"\"\"\n",
    "    xs = np.arange(-int(np.floor(xrange_val)), int(np.floor(xrange_val)) + 1)\n",
    "    return np.sum([Farbsaum(x, z, F, g, weight_func) for x in xs])\n",
    "\n",
    "def ColorFringe(x, z, F, g, weight_func):\n",
    "    \"\"\"Return an RGB tuple based on the edge functions.\"\"\"\n",
    "    return (EdgeR(x, z, F, g, weight_func),\n",
    "            EdgeG(x, z, F, g, weight_func),\n",
    "            EdgeB(x, z, F, g, weight_func))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f81044-d030-467f-918f-b01a991a89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 6: Data Calculation for Defocus Positions\n",
    "# Step size for the defocus values\n",
    "dd = 10  \n",
    "# Create an array of defocus positions along the optical axis.\n",
    "z_vals = np.arange(-defocusrange, defocusrange + 1, dd)\n",
    "\n",
    "def calculate_farbs_data(F_value, weight_func):\n",
    "    \"\"\"\n",
    "    For each z in `z_vals`, calculate the \"Farbsaumbreite\" using the binary method.\n",
    "    \n",
    "    Returns:\n",
    "        data (np.array): An array of [z, Farbsaumbreite] pairs.\n",
    "    \"\"\"\n",
    "    data = np.array([[z, Farbsaumbreite(z, F_value, 1, weight_func)] for z in z_vals])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b39a425-fe8f-4df7-82d3-2770c6dfccd2",
   "metadata": {},
   "source": [
    "# Define the grid for x_shift and tilt.\n",
    "# Adjust the number of points as needed.\n",
    "x_shift_values = np.linspace(-50, 50, num=21)  # 21 points from -50 to 50\n",
    "tilt_values = np.linspace(-0.5, 0.5, num=21)    # 21 points from -0.5 to 0.5\n",
    "\n",
    "# Storage for results: each entry is (x_shift, tilt, width_max)\n",
    "results = []\n",
    "\n",
    "# F value and weighting function selection (using Gaussian PSF)\n",
    "F_value = 8\n",
    "weight_func = gaussian_weight\n",
    "\n",
    "# Iterate over the parameter grid.\n",
    "for x_shift in x_shift_values:\n",
    "    for tilt in tilt_values:\n",
    "        # Update global CHLdata using the modified CHL curve\n",
    "        # extract_sampled_modified_values_overall returns a 2-col matrix:\n",
    "        # Column 0: wavelengths, Column 1: CHL values (floored to int)\n",
    "        CHL_matrix = extract_sampled_modified_values_overall(x_shift, tilt)\n",
    "        # Here we assume that only the CHL values (second column) are needed.\n",
    "        # Set the global variable CHLdata to these values.\n",
    "        CHLdata = CHL_matrix[:, 1]\n",
    "        \n",
    "        # Calculate the farbs data for the current parameter combination.\n",
    "        farbs_data = calculate_farbs_data(F_value, weight_func)\n",
    "        \n",
    "        # Get the maximum fringe width from the calculated data.\n",
    "        # farbs_data is assumed to be an array of [z, farbsaumbreite] pairs.\n",
    "        width_max = np.max(farbs_data[:, 1])\n",
    "        \n",
    "        # Store the result as (x_shift, tilt, width_max)\n",
    "        results.append((x_shift, tilt, width_max))\n",
    "\n",
    "# Convert the results to a NumPy array for further analysis or visualization.\n",
    "results_array = np.array(results)\n",
    "\n",
    "# Optionally, print or visualize the resulting dataset.\n",
    "print(\"x_shift, tilt, width_max\")\n",
    "print(results_array)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d04bbb82-3db1-4544-bf2c-70248b2d9d79",
   "metadata": {},
   "source": [
    "# %% Cell X+1: Plot the Parameter Sweep Results as a Colormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming results_array is already defined from the previous cell:\n",
    "# results_array columns: [x_shift, tilt, width_max]\n",
    "\n",
    "# Define the grid dimensions based on the number of x_shift and tilt values used\n",
    "num_x = len(np.unique(results_array[:, 0]))  # Number of unique x_shift values\n",
    "num_t = len(np.unique(results_array[:, 1]))  # Number of unique tilt values\n",
    "\n",
    "# Reshape the width_max data into a 2D grid.\n",
    "# Note: the outer loop was over x_shift and inner over tilt, so reshape accordingly.\n",
    "width_max_grid = results_array[:, 2].reshape((num_x, num_t))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Create an image plot. Use 'extent' to properly label the axes.\n",
    "im = plt.imshow(width_max_grid,\n",
    "                extent=[results_array[:, 1].min(), results_array[:, 1].max(),\n",
    "                        results_array[:, 0].min(), results_array[:, 0].max()],\n",
    "                origin='lower',\n",
    "                aspect='auto')\n",
    "plt.colorbar(im, label='width_max')\n",
    "plt.xlabel('tilt')\n",
    "plt.ylabel('x_shift')\n",
    "plt.title('Colormap of width_max with respect to (x_shift, tilt)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c5645-8c93-4a74-82bb-06265e2ce9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell: Fast Search for Minimum width_max using ThreadPoolExecutor\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "# Define the grid for x_shift and tilt.\n",
    "x_shift_values = np.linspace(-50, 50, num=21)  # 21 points from -50 to 50\n",
    "tilt_values = np.linspace(-0.5, 0.5, num=21)    # 21 points from -0.5 to 0.5\n",
    "\n",
    "F_value = 8\n",
    "weight_func = gaussian_weight\n",
    "\n",
    "def evaluate_params(params):\n",
    "    \"\"\"\n",
    "    Evaluate a single (x_shift, tilt) combination:\n",
    "      - Compute the modified CHL curve and update CHLdata.\n",
    "      - Calculate farbs data and extract width_max.\n",
    "    Returns (x_shift, tilt, width_max).\n",
    "    \"\"\"\n",
    "    x_shift, tilt = params\n",
    "    # Compute modified CHL values.\n",
    "    CHL_matrix = extract_sampled_modified_values_overall(x_shift, tilt)\n",
    "    # Update the global CHLdata (used by calculate_farbs_data).\n",
    "    global CHLdata\n",
    "    CHLdata = CHL_matrix[:, 1]\n",
    "    \n",
    "    # Calculate farbs data for this parameter set.\n",
    "    farbs_data = calculate_farbs_data(F_value, weight_func)\n",
    "    \n",
    "    # Compute the maximum fringe width.\n",
    "    width_max = np.max(farbs_data[:, 1])\n",
    "    return (x_shift, tilt, width_max)\n",
    "\n",
    "# Create a list of all parameter combinations.\n",
    "param_grid = [(x_shift, tilt) for x_shift in x_shift_values for tilt in tilt_values]\n",
    "\n",
    "# Use ThreadPoolExecutor to avoid pickling issues in Jupyter.\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    results = list(executor.map(evaluate_params, param_grid))\n",
    "\n",
    "results_array = np.array(results)\n",
    "\n",
    "# Find the parameter combination with the smallest width_max.\n",
    "min_index = np.argmin(results_array[:, 2])\n",
    "best_params = results_array[min_index]\n",
    "\n",
    "print(\"Minimum width_max found:\")\n",
    "print(\"x_shift: {:.2f}, tilt: {:.2f}, width_max: {:.2f}\".format(*best_params))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4404a859-e97a-460d-86ba-5ad5507da56f",
   "metadata": {},
   "source": [
    "# %% Cell: Colormap of width_max with Respect to (x_shift, tilt)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine unique grid dimensions.\n",
    "unique_x_shifts = np.unique(results_array[:, 0])\n",
    "unique_tilts = np.unique(results_array[:, 1])\n",
    "num_x = unique_x_shifts.size  # number of unique x_shift values\n",
    "num_t = unique_tilts.size      # number of unique tilt values\n",
    "\n",
    "# Reshape the width_max values into a 2D grid.\n",
    "# Note: The loop order was: for each x_shift, loop through tilts.\n",
    "width_max_grid = results_array[:, 2].reshape((num_x, num_t))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(width_max_grid,\n",
    "                extent=[unique_tilts.min(), unique_tilts.max(),\n",
    "                        unique_x_shifts.min(), unique_x_shifts.max()],\n",
    "                origin='lower',\n",
    "                aspect='auto')\n",
    "plt.colorbar(im, label='width_max')\n",
    "plt.xlabel('tilt')\n",
    "plt.ylabel('x_shift')\n",
    "plt.title('Colormap of width_max with respect to (x_shift, tilt)')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
